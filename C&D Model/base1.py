# -*- coding: utf-8 -*-
"""base1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zLaa8FO7CYJQKUEM78oQJBf_Wu9-ssHR
"""

!pip install numpy -q
!pip install pandas -q
!pip install matplotlib -q
!pip install tensorflow -q
!pip install opendatasets -q
!pip install opencv-python -q
!pip install gdown
!pip install PyDrive

#import necessary libraries
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import time
import seaborn as sns
from sklearn.metrics import roc_curve, auc, confusion_matrix
import opendatasets as od
import gdown

# Download the dataset
od.download("https://www.kaggle.com/datasets/harshwalia/birds-vs-drone-dataset")
od.download("https://www.kaggle.com/datasets/imbikramsaha/drone-bird-classification")

BATCH_SIZE = 32
IMAGE_SIZE = (128,128)

train_data_dir = "/content/drive/MyDrive/BirdVsDrone/Train"
test_data_dir = "/content/drive/MyDrive/BirdVsDrone/Test"

# Load the dataset
train_data = tf.keras.utils.image_dataset_from_directory(train_data_dir,
                                                         batch_size=BATCH_SIZE,
                                                         image_size= IMAGE_SIZE,
                                                         subset='training',
                                                         validation_split=0.1,
                                                         seed=42)

validation_data = tf.keras.utils.image_dataset_from_directory(train_data_dir,
                                                              batch_size=BATCH_SIZE,
                                                              image_size=IMAGE_SIZE,
                                                              subset='validation',
                                                              validation_split=0.1,
                                                              seed=42)

test_data = tf.keras.utils.image_dataset_from_directory(test_data_dir,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMAGE_SIZE)

class_names = train_data.class_names
class_names

# Normalize the data
train_data = train_data.map(lambda x,y:(x/255,y))
validation_data = validation_data.map(lambda x,y:(x/255,y))
test_data = test_data.map(lambda x,y:(x/255,y))

# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPool2D(),
    tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPool2D(),
    tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPool2D(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

# Train the model
start_time = time.time()

history = model.fit(train_data,
                    epochs=20,
                    validation_data=validation_data)

end_time = time.time()

# Plot training history
fig, axs = plt.subplots(1, 2, figsize=(12, 4))

axs[0].plot(history.history['accuracy'], color='teal', label='accuracy')
axs[0].plot(history.history['val_accuracy'], color='orange', label='val_accuracy')
axs[0].set_title('Accuracy')
axs[0].legend()

axs[1].plot(history.history['loss'], color='teal', label='loss')
axs[1].plot(history.history['val_loss'], color='orange', label='val_loss')
axs[1].set_title('Loss')
axs[1].legend()

plt.show()

# Evaluate model performance on test data
precision = tf.keras.metrics.Precision()
recall = tf.keras.metrics.Recall()
accuracy = tf.keras.metrics.BinaryAccuracy()

y_true = []
y_pred_probs = []

for batch in test_data.as_numpy_iterator():
    X, y = batch
    yhat = model.predict(X)
    y_true.extend(y)
    y_pred_probs.extend(yhat)

y_true = np.array(y_true)
y_pred_probs = np.array(y_pred_probs)
y_pred = (y_pred_probs > 0.5).astype(int)

precision.update_state(y_true, y_pred_probs)
recall.update_state(y_true, y_pred_probs)
accuracy.update_state(y_true, y_pred_probs)

# Calculate F1 Score
precision_val = precision.result().numpy()
recall_val = recall.result().numpy()
f1_score_val = 2 * (precision_val * recall_val) / (precision_val + recall_val)

print(f'Precision: {precision.result().numpy()}')
print(f'Recall: {recall.result().numpy()}')
print(f'Accuracy: {accuracy.result().numpy()}')
print(f"F1 Score: {f1_score_val}")

# Function to plot ROC curves
def plot_roc_curve(y_true, y_scores, label):
    fpr, tpr, _ = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')

from google.colab import drive
drive.mount('/content/drive')

# Plot ROC curve
plt.figure(figsize=(10, 6))
plot_roc_curve(y_true, y_pred_probs, 'Model')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

# Function to plot confusion matrix
def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(title)
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Plot confusion matrix
plot_confusion_matrix(y_true, y_pred, 'Confusion Matrix')

# Predict on a sample image
import cv2

image = cv2.imread("/content/birds-vs-drone-dataset/BirdVsDrone/Birds/singleBirdinsky1.jpeg")
plt.imshow(image)
plt.show()

resized_image = tf.image.resize(image, IMAGE_SIZE)
scaled_image = resized_image / 255.0

y_hat = model.predict(np.expand_dims(scaled_image, 0))

if y_hat >= 0.5:
    print(class_names[1])
else:
    print(class_names[0])

